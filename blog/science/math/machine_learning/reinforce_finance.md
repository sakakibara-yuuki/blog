---
title: "強化学習: 実践と応用"
author: "sakakibara"
description: "上手くいかないことがありましたが、コミュニティに質問して助けてもらいました！"
heroImage: "/science/science.jpg"
pubDate: 2024-05-17
tags: ["math", "深層学習", "機械学習", "強化学習", "torchrl"]
---


### 様々な強化学習のアルゴリズム
強化学習には様々なアルゴリズムが提案されている。
そこで、以下に代表的なアルゴリズムを紹介する。

- TRPO
- PPO
- DDPG
- Categorical DQN

### 経済に対する応用
#### 2010年代の研究動向
非常に興味深い応用分野として株やFXのトレードに強化学習を応用する研究がある。[^1]
トレードにおいて"予測"と"ポートフォリオ構築"の２つを合わせるタスクが考えられる。
これに対する一般的なアプローチは以下のようなものである。
[Kim, 2003; Huang et al., 2005/ Kumar and Thenmozhi, 2006; Booth et al., 2014; Moritz and Zimmermann,
2014; Krauss et al., 2017/ Teixeira and De Oliveira, 2010]

1. NNやランダムフォレストなどを用いて過去のデータから値動きを予測し
1. 予測値は売買モジュールに渡され、 予測が閾値を超えた場合は売買を行う。

この二段階のアプローチは不動の人気があり、よく採用されているのにもかかわらず、限界がある。

"これらの手法は、おそらく最適ではない" のだ。[Moody et al., 1998b]

そもそも、値動きを予測するモデルの目的関数を最小化することは投資における究極的な目標とはいえない。投資の目的は最小リスクで最大のリターンをえることである。  
また、ほとんどの場合、予測値そのものが単純に売買モジュールにわたされる。
特徴量から得られるプラスアルファの情報が十分に生かされているとは言い難いのだ。  
そして、外部環境による制約、たとえば流動性や取引コストなどは売買モジュールに組み込まれる(もしくは考慮すらされない)ことが多い。  

強化学習は予測とポートフォリオ構築を一つのフレームワークとして扱い、同時に最適化する。
さらに、環境との相互作用を通じて、流動性や取引コストなどの外部環境に対する適応性を持つことができる。

<!-- このような理由から強化学習はトレード、金融工学において非常に注目されており、50以上の論文を精査した結果、以下の採用されているアルゴリズムにはばらつきがあることが知られている。 -->
<!---->
<!-- - critic-only: 最もよく採用されているアプローチ。軸となる考えはagentが決定した行動と期待される収益の差を(批判的に)ベースとした行動の価値を学習する。(もっとうまくやれたやろ！理論上！)。agentは現在の状態を観測し、価値関数にしたがって最大の収益をもたらすであろう行動を選択する。   -->
<!-- - actor-only: 2番目によく採用されているアプローチ。agentは状態を観測し、行動する。(自分、天才なんで) このとき、期待される収益のことなんて考えない。そう、行動することで直接的に次にどう行動したらいいかを学習する。 -->
<!-- - actor-critic: 3番目によく採用されているアプローチ。actorとcriticを合わせた考え。actorは状態を観測し、actorの行動をジャッジするcriticのことを考えながら行動する。actorはcriticが良いと考える行動を選択し、同時にcriticはより判断能力を向上させる。 -->

[^1]: Fischer, Thomas G., 2018. Reinforcement learning in financial markets - a survey.

#### 2024年の研究動向
#### 研究目的(タスク)の分類
"予測"と"ポートフォリオ構築"の２つのタスクがあると述べたが、2024年では少し細分化され、以下のようなタスクが注目されている。

- "予測":
    - トレンドの予測
- "戦略最適化" : 戦略最適化
    - "リスク管理" : リスク管理
    - "ポートフォリオ構築": 裁定取引の発見

agentは取引戦略の最適化を行う。このとき、agentが行う行動には
- いつ買う・売る・保持するか
- どのように銘柄に重みをつけるか
などがある。

また、リスクの管理も行われる。
これには
- ストップロス(損切り: 損失が一定以上になったら決済すること)
- テイクプロフィット(利食い: 含み益がある状態で決済すること)
- ポートフォリオの重さの調整
が含まれる。

<!-- # action [[share, price, price_loss, price_profit, leverage]] -->

また、裁定取引機会の発見も行われる。
これには、
- 異なる満期をもつ先物の裁定取引の最適化
が含まれる。

最後に、株などのトレードの傾向の発見も行われる。
つまり、マーケット・トレンドの予測情報を得ることができる。

#### データと研究目的による分類
さらに、入手できるデータと達成目的に従って4分類される。
- 高頻度 / 低頻度
- 予測 / 戦略最適化
<!-- [1-4][19-20] -->
